# MONAD Backend Configuration

# Model Configuration
MODEL_PATH=/Users/joseph/OfflineLLM/models/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf
MODEL_CONTEXT_SIZE=2048
MODEL_N_THREADS=4

# Server Configuration
HOST=0.0.0.0
PORT=5005
DEBUG=false

# LLM Generation Parameters
MAX_TOKENS=512
TEMPERATURE=0.7
TOP_P=0.9
REPEAT_PENALTY=1.1
